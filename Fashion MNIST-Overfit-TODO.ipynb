{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist=tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test)= fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    " print(X_train.shape)\n",
    " print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "     X_val = X_test[:8000]\n",
    "     y_val = y_test[:8000]\n",
    "     X_test = X_test[8000:]\n",
    "     y_test = y_test[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(2000, 28, 28)\n",
      "(8000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    " print(X_train.shape)\n",
    " print(X_test.shape)\n",
    " print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_names=[\"T-Shirt\", \"Trousers\", \"Pullover\", \"Dress\", \"Coat\",\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " plt.figure()\n",
    " plt.imshow(X_test[100], cmap='gray')\n",
    " plt.colorbar()\n",
    " plt.title(targets_names[y_test[100]])\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization,MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "     model_Over=tf.keras.Sequential([\n",
    "         Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                input_shape=(28, 28, 1)),\n",
    "         BatchNormalization(),\n",
    "         Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "         BatchNormalization(),\n",
    "         MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "         Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "         BatchNormalization(),\n",
    "         Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "         BatchNormalization(),        \n",
    "         MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "         Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "         BatchNormalization(),\n",
    "         Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "         BatchNormalization(),    \n",
    "         MaxPooling2D(pool_size=(2, 2)),   \n",
    "        \n",
    "         Flatten(),\n",
    "        \n",
    "         Dense(1024, activation='relu'),\n",
    "        \n",
    "         Dense(512, activation='relu'),\n",
    "        \n",
    "         Dense(10, activation='softmax')\n",
    "     ])\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model_Over.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 206s 109ms/step - loss: 0.3826 - accuracy: 0.8619 - val_loss: 0.3195 - val_accuracy: 0.8805\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 207s 110ms/step - loss: 0.2565 - accuracy: 0.9083 - val_loss: 0.4258 - val_accuracy: 0.8708\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 205s 109ms/step - loss: 0.2200 - accuracy: 0.9214 - val_loss: 0.3009 - val_accuracy: 0.9032\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 207s 110ms/step - loss: 0.1904 - accuracy: 0.9308 - val_loss: 0.2911 - val_accuracy: 0.9005\n",
      "Epoch 5/15\n",
      " 241/1875 [==>...........................] - ETA: 2:58 - loss: 0.1498 - accuracy: 0.9472"
     ]
    }
   ],
   "source": [
    "history = model_Over.fit(X_train, y_train, epochs=15,batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Applying L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model_l2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l2.compile(optimizer='adam', loss='SparseCategoricalCrossentropy', metrics=['accuracy'])\n",
    "model_l2.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate metrics\n",
    "print(\"\\nEvaluating...\", flush=True)\n",
    "print('Training data:', flush=True)\n",
    "loss, acc = model_l2.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"  Training : loss %.3f - acc %.3f\" % (loss, acc))\n",
    "print('Validation data:', flush=True)\n",
    "loss, acc = model_l2.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"  Val: loss %.3f - acc %.3f\" % (loss, acc))\n",
    "print('Test data:', flush=True)\n",
    "loss, acc = model_l2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"  Testing  : loss %.3f - acc %.3f\" % (loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Droupout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout.compile(optimizer='adam',\n",
    "              loss='SparseCategoricalCrossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_dropout.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ES = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "        tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model_ES.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Stop training when there is no improvement in the validation loss for 2 consecutive epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history_ES = model_ES.fit(X_train, y_train,\n",
    "                    epochs = 10,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Data Augmentation\n",
    "\n",
    "from keras import layers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=Trousers. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'resizing_2' (type Resizing).\n\nCannot convert 'Trousers' to EagerTensor of dtype float\n\nCall arguments received by layer 'resizing_2' (type Resizing):\n  • inputs='Trousers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2ad777916401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m ])\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize_and_rescale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'resizing_2' (type Resizing).\n\nCannot convert 'Trousers' to EagerTensor of dtype float\n\nCall arguments received by layer 'resizing_2' (type Resizing):\n  • inputs='Trousers'"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 180\n",
    "\n",
    "resize_and_rescale = keras.Sequential([\n",
    "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "result = resize_and_rescale(targets_names[1])\n",
    "plt.axis('off')\n",
    "plt.imshow(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
